{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Counting Objects Everyday - Literature Models.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3Jd9zq8s-H2",
        "colab_type": "text"
      },
      "source": [
        "# Counting Everyday Objects in Everyday Scenes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDO-cs1ls-H3",
        "colab_type": "text"
      },
      "source": [
        "In this notebook it is shown how to use the ported Keras implementation of the counting models presented in the paper Chattopadhyay P. [\"Counting Everyday Objects in Everyday Scenes\"](https://arxiv.org/abs/1604.03505)\n",
        "\n",
        "All the models are implemented according to the guidelines of the authors. For the implementation of the models with more efficient pipelines and better deployment check the notebook \"Transfer Learning to Count Objects in Custom Datasets\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYB-R7-4wvFV",
        "colab_type": "text"
      },
      "source": [
        "## Download and compile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t36YLsJr9m9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r object_counting keras*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2V0FHlStX3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xf keras.tar.xz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kndGKW8p1MI2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LNT2d314tEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--WAMJSMGp--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_W6IJMiGvX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGW04B_w8R7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTS53n0gHnX7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xf VOCtest_06-Nov-2007.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfz3mw7pHa4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xf VOCtrainval_06-Nov-2007.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2c6qOcV8UqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xf VOCtrainval_11-May-2012.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGf5f_SQtnss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/object_counting/objects_counter/gt_generation/cython/')\n",
        "!python setup.py build_ext --inplace"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-v9-93fu6lZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/object_counting/objects_counter/utils/cython/')\n",
        "!python setup.py build_ext --inplace\n",
        "\n",
        "os.chdir('/content/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tr3Fytjps-H4",
        "colab_type": "text"
      },
      "source": [
        "## The different models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vELObXDs-H5",
        "colab_type": "text"
      },
      "source": [
        "The model presented in the paper are the followings (results on PASCAL VOC 07 Dataset):\n",
        "\n",
        "<br>\n",
        "<div class=\"ModelsTable\">\n",
        "    \n",
        "|Model      |Annotation     |mRMSE |\n",
        "|-----------|:-------------:|:---------:|\n",
        "|**Detect** |Bounding Boxes |0.50 ± 0.01|\n",
        "|**Glance** |Count          |0.50 ± 0.02|\n",
        "|**Aso-Sub**|Bounding Boxes |0.43 ± 0.01|\n",
        "|**Seq-Sub**|Bounding Boxes |0.42 ± 0.01|\n",
        "\n",
        "</div>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ysw4tXvs-H6",
        "colab_type": "text"
      },
      "source": [
        "## Models applied to PASCAL VOC dataset\n",
        "\n",
        "From now on, I will show you how to use the code and instantiate the different models and test them on the PASCAL VOC dataset.\n",
        "\n",
        "In each block, most of the operations are the same thanks to the flexibility of the class inspired by Object Oriented paradigm, exploiting objects ineritance and interface style."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdtygPVos-H7",
        "colab_type": "text"
      },
      "source": [
        "### Preliminary imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCDucc0Bs-H8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "# Uncomment if your GPU has not enough memory\n",
        "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "\n",
        "from object_counting.objects_counter.objects_counter import ObjectsCounter\n",
        "from object_counting.objects_counter.utils.data_generator import DataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwPb_tYAs-IB",
        "colab_type": "text"
      },
      "source": [
        "### Setting variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HenJLUFas-IC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = 'resnet152' # available: ['vgg16', 'mobilenet', 'resnet50', 'resnet152', 'inceptionresnet']b'\n",
        "classes = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
        "           'bottle', 'bus', 'car', 'cat',\n",
        "           'chair', 'cow', 'diningtable', 'dog',\n",
        "           'horse', 'motorbike', 'person', 'pottedplant',\n",
        "           'sheep', 'sofa', 'train', 'tvmonitor']\n",
        "input_shape = (224,224,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_NfGD7Ts-IE",
        "colab_type": "text"
      },
      "source": [
        "### Prediction Interpretation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydxkBXofs-IF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pretty_prediction(classes, y_pred, y_true=None):\n",
        "    \n",
        "    if y_true is not None:\n",
        "        for i in range(y_pred.shape[0]):\n",
        "            print(\"Prediction {}\".format(i))\n",
        "            for c in range(len(classes)):\n",
        "                if not y_pred[i,c] == 0 or not y_true[i,c] == 0:\n",
        "                    print(\"\\t{}: {} {}\".format(classes[c], y_pred[i,c], y_true[i,c]))\n",
        "    else:\n",
        "        for i in range(y_pred.shape[0]):\n",
        "            print(\"Prediction {}\".format(i))\n",
        "            for c in range(len(classes)):\n",
        "                if not y_pred[i,c] == 0:\n",
        "                    print(\"\\t{}: {}\".format(classes[c], y_pred[i,c]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtShzXhbs-IH",
        "colab_type": "text"
      },
      "source": [
        "## MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTdtqLJDs-II",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_model = 'asosub' # available: ['glance', 'asosub', 'asosubfc', 'seqsub', 'detect']\n",
        "model_args = {'num_hidden': 2, # valid only for glance and asosub, comment otherwise\n",
        "              #'num_bilstms': 2, # valid only for seqsub, comment otherwise\n",
        "              'hidden_size': 250,\n",
        "              'include_relu': False,\n",
        "              'weights': None}\n",
        "grid_division = (3,3) # set to (n,n) in case of asosub or seqsub\n",
        "weights = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SJCYMkks-IL",
        "colab_type": "text"
      },
      "source": [
        "### Load datasets and convert them in the correct format for the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaMKpNVOs-IL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sets = ['/content/VOCdevkit/VOC2007/ImageSets/Main/train.txt',\n",
        "        '/content/VOCdevkit/VOC2007/ImageSets/Main/val.txt',\n",
        "        '/content/VOCdevkit/VOC2007/ImageSets/Main/test.txt',\n",
        "       ]\n",
        "setnames = ['train_asosub', 'val_asosub_asosub', 'test_asosub']\n",
        "images_folder = '/content/VOCdevkit/VOC2007/JPEGImages/'\n",
        "annotations_folder = '/content/VOCdevkit/VOC2007/Annotations/'\n",
        "annotations_ext = 'xml'\n",
        "\n",
        "dataset = DataGenerator(classes,\n",
        "                        count_model=count_model,\n",
        "                        base_model=base_model,\n",
        "                        base_model_weights=weights,\n",
        "                        input_shape=input_shape,\n",
        "                        grid_division=grid_division,\n",
        "                        gt_mode={'mode': 'linear',\n",
        "                                 'std_ratio': (5, 5)})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVtshkjbulTI",
        "colab_type": "text"
      },
      "source": [
        "Load the features for the original non-end-to-end models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ujVZxq6r8bm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##############################\n",
        "#           NON-E2E\n",
        "##############################\n",
        "\n",
        "# If you want to load the data from scratch and extract the features run this cell\n",
        "\n",
        "dataset.load_dataset(sets=sets,\n",
        "                     images_folder=images_folder,\n",
        "                     annotations_folder=annotations_folder,\n",
        "                     annotations_ext=annotations_ext,\n",
        "                     setnames=setnames,\n",
        "                     h5dataset_path=None,\n",
        "                     h5saving_folder='/content/VOCdevkit/VOC2007/',\n",
        "                     h5saving_file=None,\n",
        "                     load_into_memory=False,\n",
        "                     serialize_cells=False) #set true for asosub\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcfZDGk4ICav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sets = ['/content/VOCdevkit/VOC2012/ImageSets/Main/trainval.txt']\n",
        "setnames = ['train_asosub_12']\n",
        "images_folder = '/content/VOCdevkit/VOC2012/JPEGImages/'\n",
        "annotations_folder = '/content/VOCdevkit/VOC2012/Annotations/'\n",
        "annotations_ext = 'xml'\n",
        "\n",
        "dataset_12 = DataGenerator(classes,\n",
        "                        count_model=count_model,\n",
        "                        base_model=base_model,\n",
        "                        base_model_weights=weights,\n",
        "                        input_shape=input_shape,\n",
        "                        grid_division=grid_division,\n",
        "                        gt_mode={'mode': 'linear',\n",
        "                                 'std_ratio': (5, 5)})   \n",
        "\n",
        "dataset_12.load_dataset(sets=sets,\n",
        "                     images_folder=images_folder,\n",
        "                     annotations_folder=annotations_folder,\n",
        "                     annotations_ext=annotations_ext,\n",
        "                     setnames=setnames,\n",
        "                     h5dataset_path=None,\n",
        "                     h5saving_folder='/content/VOCdevkit/VOC2007/',\n",
        "                     h5saving_file=None,\n",
        "                     load_into_memory=False,\n",
        "                     serialize_cells=False) #set true for asosub"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6qU5DpkJusQJ"
      },
      "source": [
        "Load the features for the end-to-end models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlFoOaiPs-IO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##############################\n",
        "#             E2E            #\n",
        "##############################\n",
        "\n",
        "# If you want to load the data from scratch and extract the features run this cell\n",
        "\n",
        "dataset.load_dataset_noftr(sets=sets,\n",
        "                           images_folder=images_folder,\n",
        "                           annotations_folder=annotations_folder,\n",
        "                           annotations_ext=annotations_ext,\n",
        "                           setnames=setnames,\n",
        "                           h5saving_folder='/content/VOCdevkit/VOC2007/',\n",
        "                           h5saving_file=None,\n",
        "                           load_into_memory=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLEmPImus-IR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If you already have the features extracted and saved in a HDF5 file, run this cell\n",
        "\n",
        "setnames = ['train_asosub', 'val_asosub_asosub', 'test_asosub', 'train_asosub_12']\n",
        "\n",
        "X_train_07,y_train_07 = dataset.h5features_to_memory('/content/VOCdevkit/VOC2007/{}.h5'.format(setnames[0]), gt=True)\n",
        "X_train_12,y_train_12 = dataset.h5features_to_memory('/content/VOCdevkit/VOC2007/{}.h5'.format(setnames[3]), gt=True)\n",
        "X_val,y_val = dataset.h5features_to_memory('/content/VOCdevkit/VOC2007/{}.h5'.format(setnames[1]), gt=True)\n",
        "X_test,y_test = dataset.h5features_to_memory('/content/VOCdevkit/VOC2007/{}.h5'.format(setnames[2]), gt=True)\n",
        "\n",
        "X_train = np.concatenate([X_train_07, X_train_12])\n",
        "y_train = np.concatenate([y_train_07, y_train_12])\n",
        "\n",
        "X_train = np.reshape(X_train, (-1, 2048))\n",
        "X_val = np.reshape(X_val, (-1, 2048))\n",
        "X_test = np.reshape(X_test, (-1, 2048))\n",
        "y_train = np.reshape(y_train, (-1, 20))\n",
        "y_val = np.reshape(y_val, (-1, 20))\n",
        "y_test = np.reshape(y_test, (-1, 20))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ9IbNwss-IU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Training data size: {}'.format(X_train.shape))\n",
        "print('Validation data size: {}'.format(X_val.shape))\n",
        "print('Test data size: {}'.format(X_test.shape))\n",
        "print('Training gt size: {}'.format(y_train.shape))\n",
        "print('Validation gt size: {}'.format(y_val.shape))\n",
        "print('Test gt size: {}'.format(y_test.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOx3wSATs-IZ",
        "colab_type": "text"
      },
      "source": [
        "### Instantiate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxBWB7mGs-IZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input shape is taken from the first dataset, and starting from the second index\n",
        "# because the model don't need the number of samples in the input shape\n",
        "K.clear_session()\n",
        "OC_model = ObjectsCounter(base_model,\n",
        "                          count_model,\n",
        "                          classes,\n",
        "                          model_args,\n",
        "                          input_shape=X_train.shape[1:],\n",
        "                          e2e=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn9GH5CQtVC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.losses import poisson\n",
        "\n",
        "# OC_model.compile(lr=0.0001)\n",
        "\n",
        "OC_model.counting_model.model.compile(Adam(lr=0.001), loss='mse')\n",
        "OC_model.counting_model.model.summary()\n",
        "weights = None\n",
        "if weights is not None:\n",
        "  OC_model.load_weights(weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbhm54sXs-Ic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = OC_model.train(X_train,\n",
        "                         y_train,\n",
        "                         batch_size=100,\n",
        "                         epochs=200,\n",
        "                         initial_epoch=0,\n",
        "                         steps_per_epoch=None,\n",
        "                         val_data=(X_val, y_val),\n",
        "                         validation_steps=None,\n",
        "                         lr_schedule=None,\n",
        "                         checkpoint_folder='weights/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7nvVbRJg9Uw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fine tune the model\n",
        "OC_model.counting_model.defreeze_layers(0)\n",
        "OC_model.compile(lr=0.0001)\n",
        "OC_model.load_weights(weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFlgoFDInZje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "OC_model.train(X,\n",
        "               y,\n",
        "               batch_size=25,\n",
        "               epochs=50,\n",
        "               initial_epoch=0,\n",
        "               steps_per_epoch=None,\n",
        "               val_data=(X_val,y_val),\n",
        "               validation_steps=None,\n",
        "               lr_schedule=None,\n",
        "               chekpoint_folder='weights/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZ18X2g_s-Ie",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate model\n",
        "\n",
        "<br>\n",
        "\n",
        "In this section, we load the test set, we load the trained weights of the model and then evaluate it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Fa_BliPs-Io",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load weights to the model\n",
        "K.clear_session()\n",
        "OC_model = ObjectsCounter(base_model, count_model, classes, model_args, input_shape=X_test.shape[1:], e2e=False)\n",
        "OC_model.compile()\n",
        "#OC_model.load_weights('weights/Glanceweights_epoch-9895_val_loss-0.3736.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0_TjsF6s-Is",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metrics = OC_model.evaluate(X_test, y_test, 25)\n",
        "print('Loss: {}'.format(metrics))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LuSJREVoXkSy",
        "colab": {}
      },
      "source": [
        "predictions = OC_model.predict(X_test)\n",
        "print(predictions.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SvF008xqhNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_grouped = np.round(np.reshape(y_test, (-1, 9, len(classes))).sum(axis=1))\n",
        "print(y_test_grouped.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CfWr724gXkS-",
        "colab": {}
      },
      "source": [
        "RMSE = np.sqrt(np.mean((predictions-y_test_grouped)**2))\n",
        "print(\"RMSE: \", RMSE)\n",
        "mRMSE = np.mean(np.sqrt(np.mean((predictions-y_test_grouped)**2, axis=0)))\n",
        "print(\"mRMSE: \", mRMSE)\n",
        "m_relRMSE = np.mean(np.sqrt(np.mean(((predictions-y_test_grouped)**2)/(y_test_grouped+1), axis=0)))\n",
        "print(\"m_relRMSE: \", m_relRMSE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Uvshe_ZZXkTA",
        "colab": {}
      },
      "source": [
        "print(\"The first number is the prediction, the second number is the ground truth.\\n\")\n",
        "pretty_prediction(classes, np.round(predictions[:15]), y_test_grouped[:15])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}